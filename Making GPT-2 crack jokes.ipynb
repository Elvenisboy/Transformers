{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making GPT2 crack jokes\n",
    "\n",
    "This is simple experimental notebook for fine-tuning pretrained GPT2 model on jokes dataset. Let's see if it can learn to crack some jokes on it's own. \n",
    "\n",
    "For this purpose I will use pretrained models from huggingface [transformers repository](https://github.com/huggingface/transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using [GPT2LMHeadModel()](https://github.com/huggingface/transformers/blob/079bfb32fba4f2b39d344ca7af88d79a3ff27c7c/transformers/modeling_gpt2.py#L472) class, which is modified [GPT2Model()](https://github.com/huggingface/transformers/blob/079bfb32fba4f2b39d344ca7af88d79a3ff27c7c/transformers/modeling_gpt2.py#L320) for language modeling.\n",
    "\n",
    "The only difference is added linear layer, which will transform the output embedding into logits (embedding size -> vocabulary size) which will be used for predicting the output words.\n",
    "\n",
    "First I will do a small GPT2 model experiment to see if I have understood everything correctly and I can generate some text using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 22:30:42.409156 4458931648 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /Users/martinsf/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I1029 22:30:42.412081 4458931648 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /Users/martinsf/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I1029 22:30:43.140658 4458931648 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /Users/martinsf/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
      "I1029 22:30:43.144229 4458931648 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "I1029 22:30:43.637360 4458931648 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /Users/martinsf/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to first select topN tokens from the probability list and then based on the N word distribution\n",
    "# select random token ID\n",
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
    "    choice = np.random.choice(n, 1, p = top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I prepare and tokenize the text which the model should start with continue itself. Then I run the model X iterations to add one token to the list in each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. It is the world that has been made into an object of fascination, and that you must confront. It is the world that is always there to keep you from being caught up in the truth. The Matrix is the place where you must fight to keep your eyes open and to keep yourself in your own mind... and to be a better man. And to be a better man.\n",
      "\n",
      "I have a feeling that you have seen the truth. And you know what that means. I've seen it\n"
     ]
    }
   ],
   "source": [
    "cur_ids = torch.tensor(tokenizer.encode(\" The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. \")).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in range(100):\n",
    "        outputs = model(cur_ids, labels=cur_ids)\n",
    "        loss, logits = outputs[:2]\n",
    "        softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(only one) batch and the last predicted embedding\n",
    "        next_token_id = choose_from_top(softmax_logits.numpy(), n=5) #Randomly(from the given probability distribution) choose the next word from the top n words\n",
    "        cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long() * next_token_id], dim = 1) # Add the last word\n",
    "\n",
    "    output_list = list(cur_ids.squeeze().numpy())\n",
    "    output_text = tokenizer.decode(output_list)\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For safety will save this masterpiece in a notebook cell\n",
    "\n",
    "*The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. It is the world that has been made into an object of fascination, and that you must confront. It is the world that is always there to keep you from being caught up in the truth. The Matrix is the place where you must fight to keep your eyes open and to keep yourself in your own mind... and to be a better man. And to be a better man.*\n",
    "\n",
    "*I have a feeling that you have seen the truth. And you know what that means. I've seen it*\n",
    "\n",
    "### Not bad. The model works and now we are ready to teach the GPT2 some sense of humor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first step is to find and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "\n",
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, jokes_dataset_path = 'jokes_dataset/'):\n",
    "        super().__init__()\n",
    "\n",
    "        reddit_jokes_path = os.path.join(jokes_dataset_path, 'reddit_jokes.json')\n",
    "\n",
    "        with open(reddit_jokes_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.joke_list = []\n",
    "        self.end_of_text_token = \"<|endoftext|>\"\n",
    "\n",
    "        for idx, joke_json in enumerate(data):\n",
    "            joke_str = f\"{joke_json['title']} {joke_json['body']}{self.end_of_text_token}\"\n",
    "            self.joke_list.append(joke_str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.joke_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.joke_list[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Scientists have revealed today that they have found a new drug for depressed lesbians.. .. It's called Trydixagain.<|endoftext|>\"]\n",
      "['Huehuehue SaturationSaturationSaturation<|endoftext|>']\n",
      "['My friend had a funeral for her baby who was killed by a lawnmower... I hope he Rests In Pieces.<|endoftext|>']\n",
      "[\"My kids will be friends with people of all colors of the rainbow. That means no black people.\\n\\n\\n(Credit goes to a person on either America's Got Talent or Britain's Got Talent, can't remember which)<|endoftext|>\"]\n",
      "[\"Why didn't Princess Diana have very many friends on Xbox Live? All she does is stay on the dashboard.<|endoftext|>\"]\n",
      "[\"Who's the shittiest pro basketball player? LeBrown James<|endoftext|>\"]\n",
      "[\"I called the rape hotline today Apparently it's only for victims<|endoftext|>\"]\n",
      "['ADELE WAS BUSTED FOR DRUG DEALING! Yep - they lifted her skirt and found 100 pounds of crack.<|endoftext|>']\n",
      "['Today my boss fondled my genitals! Being self-employed is great.<|endoftext|>']\n",
      "[\"Never date an Olympic Athelete They're all gold diggers<|endoftext|>\"]\n",
      "['How many Dungeons & Dragons players does it take to screw in a light bulb? A wizard to cast Reduce Person and Teleport multiple times, one experienced player to point out that the spell Reduce Person requires a pinch of powdered iron per cast, a DM to tell the experienced player to shut up, and two now very small, teleported halflings to do the nasty.<|endoftext|>']\n",
      "[\"Did you hear the one about the latest terrorist attack in France? It wasn't very Nice of them.<|endoftext|>\"]\n",
      "[\"I am getting around to writing my essay on herbs for my botany class... It's about thyme<|endoftext|>\"]\n",
      "['A teenager wants to borrow his parents car to pick up his date. His dad suggests he takes the family tandem bicycle instead. \"But dad\" said the son, \"I can\\'t pick up my date on a tandem bike. It\\'s dorky, and we\\'ll never get to the movies in time.\"\\n\\nThe dad shook his head. \"Trust me son when there\\'s two people riding, you can burn through some serious rubber.\"<|endoftext|>']\n",
      "[\"What is a neckbeard's favorite type of wood? m'hogany<|endoftext|>\"]\n",
      "['Why did the Red Hot Chili Peppers cross the road? Why did the Red Hot Chili Peppers cross the road? Because they wanted to be taken to the other side.   <|endoftext|>']\n",
      "[\"What's orange and sounds like a parrot? What's orange and sounds like a parrot?\\n\\nA carrot.<|endoftext|>\"]\n",
      "['A man is looking to spice things up... A man is getting bored with the same old same old, so he goes to a sex shop, looking to spice things up.\\n\\n\"How can I help you?\" a pretty blonde at the counter asks.\\n\\n\"I need half a cup of brown sugar, 2 tablespoons of chili powder, 1 tablespoon of paprika, a pinch of pepper, salt, cinnamon, and 1 teaspoon of cayenne pepper.\"\\n\\n\"Sir,\" the blonde explains, horrified. \"You realize this is a sex shop, right? I can\\'t imagine what you think to do those. Cayenne pepper? Ouch!\"\\n\\n\"I read about it online,\" the man explains. \"I have the recipe right here.\" He pulls a piece of paper out of his back pocket and reads the title to her:\\n\\n\"How to spice up your spare rib rub.\"<|endoftext|>']\n",
      "['So a guy walks into a cow Moo<|endoftext|>']\n",
      "['You and a friend Jack go horse back riding. You and a friend Jack go horse back riding. Jack is short and cannot get off his Horse. Would You help Jack Off His Horse!!??<|endoftext|>']\n",
      "['The Band \" The Ghost Inside \" bus was just involved in a fatal crash I guess that means there could literally be a Ghost Inside, the bus.<|endoftext|>']\n",
      "['Just seen the grave of the woman from \\'My Fair Lady\\'. It says \"Here lies a Doolittle\".<|endoftext|>']\n",
      "['Wong number I asked a sexy Chinese girl for her number.  She replied excitedly, \"Sex, sex, sex, free sex tonight!\"\\nI thought \"OMG, Wow!\"\\nThat was before her friend chimed in, \"She means \\'6663629\\'\".\\n;-(<|endoftext|>']\n",
      "['So my mate has started dating twins! I asked him the other day \"how do you tell them apart?\"\\n\\nHe said \\n\\n\"Well, Stacy is the blonde with a perfect ass, great tits, and a fantastic figure...\\n\\n\\n... And Brian\\'s got a cock\" <|endoftext|>']\n",
      "['Die Hard What happens when you overdose on viagra<|endoftext|>']\n",
      "[\"This morning as I was buttoning my shirt... ...a button fell off.\\n\\nAfter that, I picked up my briefcase, and the handle fell off.\\n\\nThen I went to open the door, and the doorknob fell off.\\n\\nI went to get into my car, and the door handle came off in my hand.\\n\\nNow I'm afraid to pee.<|endoftext|>\"]\n",
      "['Ask me these three questions and I\\'ll answer... A musician sits in a bar, talking to his friend. He says to the friend: \"Ok man, you have to ask me thse three questions, and I will answer them: \\n\\n1. What\\'s your name\\n2. What instrument do you play\\n3. what is your weakness\\n\\nOk?\" - Ok, the friend says. And he fires away:\\n\\n\"Question 1: What is your name?\" \"HANK!\" the musician answers.\\n\"Question 2: What instrument do you play?\" \"THE DRUMS!\" the musician triumphantically shouts out loud.\\n\\n\"Allright, last question\" What is your weakness?\"<|endoftext|>']\n",
      "['How do you know if a pepper is starting a fight with you? It gets jalapeño face.<|endoftext|>']\n",
      "['Why did the math student fail his exam? He needed to sketch the sine and cuisine graphs but only knew how to do cos(-x)<|endoftext|>']\n",
      "['I got a pay rise in my job. At the end of the day, I went to the pub and bought a drink for everyone there.\\n\\nI like to be generous, even if they did feel a bit weird sharing the same pint.<|endoftext|>']\n",
      "['What is the greatest show of trust in a person? Letting a cannibal give you a blowjob.<|endoftext|>']\n",
      "['Who farted? <|endoftext|>']\n",
      "[\"What's the difference between a raccoon and a boner? I don't have a raccoon.<|endoftext|>\"]\n",
      "[\"have you ever tasted african food? don't worry if you haven't, neither have they<|endoftext|>\"]\n",
      "['So this hot blonde walks up to the bartender and asks for a double entendre So he gives it to her<|endoftext|>']\n",
      "[\"If I were cloned I'd be beside myself with confusion. Really, I'd probably see double. <|endoftext|>\"]\n",
      "['[NSFW] A joke wiretapped from out former minister of foreign affairs A man goes into the new brothel. He is vigourously greeted by the pimp who shouts:\\n\\n\"Come in, come in, we have the best prices! $15 for a handjob, blowjob $25, anal $30!\"\\n\\n\"Wow, these are good prices. How much for good old pussyfucking? \"\\n\\n\"Well, we ain\\'t got that yet, I\\'m still alone here.\"<|endoftext|>']\n",
      "['Bigger isn\\'t always better! Three friends on a boat cruise find themselves stranded on an isolated tropical island.\\nThey fight their way through the dense jungle until they are captured by a tribe of shrunken phallus worshiping Amazon Warmaidens.\\n\\nThe Amazons take the three friends to their Queen, who tells them they must forage in the jungle to seek a worthy offering for the Wang God, by noon the next day.\\n\\nShe informs them that they will not only be free to go after the ensuing ritual of tribute, but they will also take the three of them back to civilisation on the tribes own canoe.\\nThe Three friends set off into the jungle early the next day. \\n\\nIt\\'s a long hot day by near noon, so they struggle almost dehydrated back to the village, where they are to present their offerings... The first two friends arrive a little early, and the ritual begins...\\n\\nFour amazons hold down friend number one, and check his canvas bag for the offering... \\nHe\\'s brought a bunch of grapes.\\n\\nThe Queen shakes her head and the amazons proceed to insert the grapes one by one into the first friends butt. Although a little awkward he is grateful in retrospect that he brought grapes.\\n\\nThey move over the second friend, who has brought a cucumber...\\nThe Queen shakes her head, and the amazons proceed to inch the average sized cucumber into his butt..\\nTo everyones surprise, he is laughing himself almost to death\\n\"What\\'s wrong with you man??? Why are you laughing at the fact you\\'re being cucumbered?\"\\nHe replies...\\n\\n\"I\\'m thinking of our other friend, He\\'s bringing a watermelon\"...<|endoftext|>']\n",
      "[\"What are a clumsy person's favorite flowers? Oopsie daisies.<|endoftext|>\"]\n",
      "[\"What's the bare minimum? One bear.<|endoftext|>\"]\n",
      "['What do you call a big music festival with no instruments? Acoachella<|endoftext|>']\n",
      "['What do you call the second-most hated politician in America? Madam President.<|endoftext|>']\n",
      "['What time do philosophers like to visit the shopping mall? At the Schopenhauer. <|endoftext|>']\n",
      "['Story of my life Dr: Have you been getting enough exercise?\\n\\nMe: Does sex count as exercise?\\n\\nDr: Yes.\\n\\nMe: No.<|endoftext|>']\n",
      "[\"Jokes (Water) Teacher: What is the formula for water? \\nStudent: H, I, J, K, L, M, N, O\\nTeacher: That's not what I taught you.\\nStudent: But you said the formula for water was...H to O. \\n😀😀😀😀<|endoftext|>\"]\n",
      "['How do u get a pool table to laugh? tickle its balls.<|endoftext|>']\n",
      "['Why an Irish man might vote for Donald Trump \\u200bBecause he thinks his Capital will keep on Dublin\\u200b\\u200b under his presidency\\n<|endoftext|>']\n",
      "[\"Why didn't they let Voldermort play quidditch? ...because he'd always just Slytherin the grass.<|endoftext|>\"]\n",
      "['You guys wanna hear a joke? Lil Wayne<|endoftext|>']\n",
      "[\"Confession A guy comes to a Priest:\\n\\n- Father, I've sinned.\\n- What is it, my son?\\n- I scammed a Jew\\n- That's not a sin, son.\\n- No?\\n- It's a miracle.<|endoftext|>\"]\n",
      "['POKER ANIMALS Q: What animal should you never play cards with?\\nA: A cheetah!<|endoftext|>']\n",
      "[\"I had a one night stand with a girl who was missing a limb Afterwards she wasn't too happy with me, we got off on the wrong foot.<|endoftext|>\"]\n",
      "['What is condemned and overused yet as inescapable as a black hole? clickbait -_-<|endoftext|>']\n",
      "['Doctor my dick has turned orange.. A man walks into a doctors office and says \"doc my dicks turned orange!\" So the doctor says \"well have you had unprotected sex? Or done any illicit drugs?\" The man replies \"no doc I\\'ve been home all week watching movies and eatin cheetos.\"<|endoftext|>']\n",
      "['A motorist was pulled over by a traffic cop. \"Excuse me, sir,\" said the cop. \"Do you realize your wife fell out of the car two miles back?\"\\n\\n\"Thank God,\" he said. \"I thought I\\'d gone deaf!\"<|endoftext|>']\n",
      "['Mahatma Ghandi ...as many people know, walked barefoot most of the time, leading to an impressive set of calluses on his feet. He also ate very little, which made him rather frail and with his odd diet, he suffered from bad breath. This made him a super calloused fragile mystic hexed by halitosis.<|endoftext|>']\n",
      "['Why, in the United States, do we not have the letter \"u\" in words like \"favourite\" and \"colour\"? Because fuck u and no one likes u, that\\'s why.<|endoftext|>']\n",
      "['Did you hear the one about the three holes in the ground? Well, well, well...<|endoftext|>']\n",
      "['Milk Cows and Leprechauns A poor Irish family of five (father, mother, and three sons) live out in the country side, and their only source of income comes from just one milk cow. Everyday, the father wakes early in the morning to go milk the cow, and every Friday, he brings the milk to the market, and comes home with just enough money for his family to get by.\\n\\nOne morning, the father wakes up and heads out to the barn. He opens the door, but only to find the milk cow dead. The father\\'s distraught, and all he can think about is the fact that he can no longer support his family. In his current state, the father climbs into the rafters of the barn and hangs himself.\\n\\nThen the mother wakes up. She heads out to the barn, only to find her husband\\'s body and the dead milk cow. She was distraught, and all she could think about was the fact that the love of her life was dead. So she walked down to the nearby stream and threw herself in.\\n\\nThen the eldest son wakes up. He walks out to the barn and finds his dead father and the dead milk cow. Then he goes down to the stream and finds his mother\\'s body washed up on the shore. Standing over her body is gorgeous female leprechaun who was just passing through. She looks at the son and asks, \"Having a rough day?\"\\n\\nHe shrugs his shoulders, \"Yeah, you could say that.\"\\n\\nThe female leprechaun thinks over the boy\\'s situation, and decides to cut him a deal. \"How about this,\" she says. \"If you can make love to me ten times in a row without stopping, I\\'ll help you out by bringing your family back, and I\\'ll even revive your precious milk cow.\" \\n\\nThe son thinks to himself, \"I\\'m in the prime of my youth. I can do this.\"\\n\\nHe tries, fails, and she kills him\\n\\nThen the middle son wakes up. He finds the dead dad, the dead milk cow, and goes to the river where he finds his mother, brother, and the beautiful female leprechaun. She asks him, \"Having a rough day?\"\\n\\n\"Yeah, you could say that.\"\\n\\nShe decides to make him the same deal; \"If you can make live to me ten times in a row without stopping, I\\'ll bring back everyone, including the milk cow.\"\\n\\nThe son thinks to himself, \"I\\'m I vigorous young man. I can do this.\"\\n\\nHe tries, fails, and she kills him\\n\\nThen the youngest son wakes up. He finds the dead dad, the dead milk cow, and goes to the river where he finds his mother, brothers, and the beautiful female leprechaun. She asks him, \"Having a rough day?\"\\n\\n\"Yeah, you could say that.\"\\n\\nShe makes him the same deal; \"If you can make live to me ten times in a row without stopping, I\\'ll bring back everyone, including the milk cow.\"\\n\\nThe son stands there pondering her offer, then asks, \"Can I make you a counter offer?\"\\n\\nShe shrugs. \"I don\\'t see why not.\\n\\n\"Okay. What would you do if I made love to you _fifteen_ times in a row?\"\\n\\nThe leprechaun laughs herself to the brink of tears, until she realizes that he\\'s being serious. \"Well, if you can manage that, I\\'ll bring everyone back to life, including the milk cow, and I\\'ll also give your family a pot of gold.\"\\n\\nHe nods his head, then presents another counter offer. \"What if I make love to you _twenty_ times in a row?\"\\n\\n\"Well, if you can manage that, I\\'ll bring everyone back to life, including the milk cow, I\\'ll give your family a pot of gold, and I\\'ll put a mansion where your house is.\"\\n\\nHe considers her offer, then agrees to the deal. As she begins to remove his clothes, he stops. \"I just have one last question.\"\\n\\n\"And that is?\"\\n\\n\"If I make love to you twenty times in a row, what\\'s to stop you from dying from it?\"\\n\\nThe leprechaun just looks at the boy, confused by his question. \"What on earth would make you think I would die from it?\"\\n\\nThe son shrugs his shoulders, and says, \"I just assumed it would. I mean, how do you think the milk cow died?\"<|endoftext|>']\n",
      "['How are Fabio and a bagel the same? Great lox<|endoftext|>']\n",
      "[\"Why is Donald Trump's favorite cuisine Canadian? Because he loves to have a mouthful of Poutine. <|endoftext|>\"]\n",
      "['How does a racist laugh? He sniggers.<|endoftext|>']\n",
      "['I want to die peacefully in my sleep like my grandfather But not like the rest of this joke, getting beaten like a dead horse<|endoftext|>']\n",
      "['What is the favorite scientific unit of the French? RPM ( Revolutions Per Minute )<|endoftext|>']\n",
      "[\"Don't break anybody's heart, they have only one........ Break their bones, they have 206. <|endoftext|>\"]\n",
      "['I like my coffee like I like my slaves. Free<|endoftext|>']\n",
      "['Three girlfriends get lost while driving through the desert. Suddenly, the car runs out of gas and leaves them stranded in the middle the hot desert. They decide that they should split up and look for help. But before they go, they each take a part of the car with them to help them on their journey. \\n\\nThe brunette friend goes first. She takes the car battery and car horn. \"I can use this to attract attention and be rescued!\" \\n\\nThe redhead goes next. She takes the car hood. \"I can use it to slide down the sand dunes faster and also to provide me shade for when I\\'m tired.\" \\n\\nThe blonde goes last. She takes the car door and starts heading out on her journey. \\n\\n\"Why on earth are you taking the car door?\" her friends ask. \\n\\n\"Oh, simple. If I get too hot on my journey, I can roll down the windows.\"<|endoftext|>']\n",
      "['\"Will you spend the rest of my life with me?\" \"That depends.  When are you going to die?\"<|endoftext|>']\n",
      "['Touching story There is a boy and girl, the boy touched the girl, girl touched the boy. What a touching story. <|endoftext|>']\n",
      "[\"[THIS IS A REQUEST; DO NOT UPVOTE] Does anyone have a joke where the audience of the joke says the punchline? If this isn't the right place for this, kindly redirect me.<|endoftext|>\"]\n",
      "[\"What's Irish and stays on your back porch all year? Patty O'Furniture<|endoftext|>\"]\n",
      "[\"Knock Knock Who's there?\\nA little Asian girl with special needs trying to sell you dildos.<|endoftext|>\"]\n",
      "['A man visits the doctor... And the doctor asks,\"What seems to be the problem?\", and the man says,\"well, it\\'s turns out that my penis has turned orange.\" So the doctor takes a look, and he cannot figure out what it could be. The doctor says,\"I\\'m not sure what what the problem is. What have you been doing for the past 48 hours? The man replies,\"Just looking at porn and eating Cheetos.\"<|endoftext|>']\n",
      "['The sperm count. There was an elderly man whose efforts to get his young wife pregnant had failed. So, he went to the doctor to have a sperm count done. \\n\\nThe doctor told him to take a specimen cup home, fill it, and bring it back the next day. \\n\\nThe elderly man came back the next day with an empty specimen cup.\\n\\nThe doctor asked, \"What was the problem?\" \\n\\nThe elderly man replied, \"Well, I tried with my right hand...nothing. So, I tried with my left hand..nothing. My wife tried with her right hand...nothing. Her left hand...nothing. Her mouth...nothing. Then my wife\\'s friend tried. Right hand, left hand, mouth....still nothing. \\n\\nOn hearing this the doctor said, \"Wait a minute! You mean your wife\\'s friend tried too?\" \\n\\nThe elderly man responded, \"Yeah, and we still couldn\\'t get the lid off that damn cup!\"\\n<|endoftext|>']\n",
      "['What do you say when somebody cuts in front of you in line for Vietnamese noodles? Hey, pho queue, dude<|endoftext|>']\n",
      "['Man creates taser for sheep What happens next will SHOCK ewe!<|endoftext|>']\n",
      "[\"What is the shit you didn't see? The shit you stepped on<|endoftext|>\"]\n",
      "['A dog attacks a little girl A man is walking in Central park in New York sees a little girl being attacked by a pit bull dog.  \\nHe runs over and starts fighting with the dog.  \\nHe succeeds in killing the dog and saving the girl\\'s life.  \\nA journalist arriving soon takes pictures and says: \\\\- \"You are a hero, tomorrow you can read in the  newspapers: Brave New Yorker saves the life of little girl\".  \\nThe man says: \\\\- \"But I am not a New Yorker!\"  \\n\\\\- \"Oh, then it will say in newspapers in the morning: Brave American saves life of little girl.\"  \\n\\\\- \"But I am not an American!\" says the man.  \\n\\\\- \"Oh, where are you from then?\"  \\n\\\\- \"I am from Iraq\".\\n\\nSo the next day newspapers reads \"Dangerous Islamic terrorist kills innocent American dog in front of a little girl\".<|endoftext|>']\n",
      "[\"Have you heard about the newest trend of restaurants serving Lion Burgers? Apparently, it's causing quite the uproar.<|endoftext|>\"]\n",
      "[\"I saw a documentary about beavers... It was the best dam program I've seen in a while<|endoftext|>\"]\n",
      "['What do you call a biker gang of bisexual Norse monarchs? The Bikings.<|endoftext|>']\n",
      "[\"I have a pretty good memory.. I'd say its about a 9/11. I never forget<|endoftext|>\"]\n",
      "['What are the similarities between fat chicks and bricks? they both get laid by mexicans<|endoftext|>']\n",
      "[\"Give a man a jacket... And he'll be able to leave the house.\\n\\nTeach a man to jacket, and he'll never leave the house.<|endoftext|>\"]\n",
      "['My great-grandmother lived to be 106 and never needed glasses. She always just drank straight from the bottle.<|endoftext|>']\n",
      "['I went to a nudist casino... ...I lost my shirt at the poker tables.<|endoftext|>']\n",
      "[\"What's the difference between a dirty bus stop and a lobster with a boob job? Ones a rusty bus station and the other is a busty crustacean!\\n\\nahahhahahahahah <|endoftext|>\"]\n",
      "[\"What's blue and fucks old ladies? Me in my lucky blue coat.<|endoftext|>\"]\n",
      "[\"Did you see that blind guy walking down the street? No? Well he didn't see you either.<|endoftext|>\"]\n",
      "['I have sex almost every night! Almost Monday night, almost Tuesday night...<|endoftext|>']\n",
      "['Masturbation <|endoftext|>']\n",
      "['The masochist asks the sadist: please hurt me. The sadist answers: No! <|endoftext|>']\n",
      "['If I had a dime... If I had a dime for every time someone gave me a penny for my thoughts…I’d CHANGE the world!\\n\\n(Please hold your applause)<|endoftext|>']\n",
      "[\"There's safety in numbers. Unless there are 6,000,000 of you.\\nAnd you're Jews.<|endoftext|>\"]\n",
      "['My first joke, probably sucks A blind man was always turned down by women because of his disability. He knew one thing though, that he had an abnormally large erection. Knowing he couldn\\'t successfully have a relationship, and use his hammer properly, he asked one of his dear friends to bring him to \"pleasure palace\", a local sex facility. \\n\\nThey go to the place and his friend says to the woman behind the desk, without his blind friend hearing, \"my friend here is blind, but he claims you will not be disappointed.\" So the woman agrees and brings him into a room. She pulls his pants down and wows about his erection. She knew she couldn\\'t handle it so she brought in another woman. She couldn\\'t handle it and told the boss. The boss comes in to take a look at it and tells the blind mans friend to take him somewhere else. He only knew one other place to find a vagina big enough to fulfill  his wishes. So he took him to your mothers house. \\n\\n<|endoftext|>']\n",
      "['Now that gay marriage is legal, my uncle can marry his boyfriend Dre! What a double entendre!\\n\\n    I made this up and am very proud.<|endoftext|>']\n",
      "['A Young Man Asks His Father About His Fiance A young man from West Virginia goes up to his dad and says, \"Pa, I am really concerned about my fiance.\"\\n \\nHis dad asks him to tell him what the problem is, he says, \"Well Pa, I just don\\'t know what to do, I just found out she is a virgin.\" \\n\\nHis dad says, \"Dump her, if she ain\\'t good enough fer her own kin, she ain\\'t good enough fer ours.\"<|endoftext|>']\n",
      "[\"A funny 1-liner I'm more tired than the Michelin Man.\\n<|endoftext|>\"]\n",
      "[\"what did the two bros talk about? Nothing, one's Axe scent was too strong for the other.<|endoftext|>\"]\n",
      "['Two sides of hummus decided to go out to eat Two sides of hummus decided to go out to eat.  Once they finished eating, they said, \"chickpeas!\"<|endoftext|>']\n",
      "['spez <|endoftext|>']\n",
      "['I\\'m bad at this, but here we go So one day I was walking to the store; because I was really craving some fruit. I went into the store and talked to the irish clerk who\\'s name was Ap.\\n\\nSo I asked the clerk if he had any fruit. He said \"sorry man, I don\\'t have any on me.\"\\n\\nEternally disappointed, I walked out of the store. But then I saw Ap leaving the store through the side for his lunch break. Ap broke out his lunch box and what did he pull out? Some fruit.\\n\\nI angrily walked up to him yelling \"Ap you\\'re caught!\" Ap then turned to me and said \"Nah man, it\\'s a pear\"<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "for idx,joke in enumerate(joke_loader):\n",
    "    print(joke)\n",
    "    if idx>100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 64\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_STEPS = 10000\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I think volcanoes are over-reacting <|endoftext|>']\n",
      "tensor([[   40,   892, 17516,  3028,   389,   625,    12,   260, 27362, 50256]])\n",
      "tensor(5.3228, grad_fn=<NllLossBackward>)\n",
      "['Yoda\\'s last name is \"Layheewho.\" <|endoftext|>']\n",
      "tensor([[   56, 11329,   338,   938,  1438,   318,   366, 23763,   258,   413,\n",
      "          8873,   526, 50256]])\n",
      "tensor(5.9632, grad_fn=<NllLossBackward>)\n",
      "[\"Kids these days Kids these days are so involved in their gadgets. I use to babysit this kid who would do whatever I tell him before he got his hands on that ipad. Now it's like he can't even hear me when I tell him to pass me the remote.<|endoftext|>\"]\n",
      "tensor([[40229,   777,  1528, 17476,   777,  1528,   389,   523,  2950,   287,\n",
      "           511, 35281,    13,   314,   779,   284, 46711,   270,   428,  5141,\n",
      "           508,   561,   466,  4232,   314,  1560,   683,   878,   339,  1392,\n",
      "           465,  2832,   319,   326, 20966,   324,    13,  2735,   340,   338,\n",
      "           588,   339,   460,   470,   772,  3285,   502,   618,   314,  1560,\n",
      "           683,   284,  1208,   502,   262,  6569,    13, 50256]])\n",
      "tensor(3.8882, grad_fn=<NllLossBackward>)\n",
      "[\"INDIAN BRAIN vs JAPANESE BRAIN - By Dr Somdutt Prasad In Japan, in a soap manufacturing company the soap blocks were made,\\nthen wrapped in a wrapping paper automatically on an assembly conveyer belt\\nand finally packed in cartons...\\nMany a times it happened that the wrapping machine wrapped the paper without soap. i.e. you had an empty packet without soap.\\nTo rectify this problem the Japanese company bought a X-ray scanner from the US for $60,000 to check on the assembly line whether the container contained soap and wasn't empty.\\nA similar problem happened at Nirma soaps, in Ahmedabad in INDIA.. Guess what they did????\\nThey bought a bajaj fan costing around Rs.1500/- and placed it on the edge of the assembly line.\\nThe empty wrappers, without soaps just blew away!!!\\nAnd You Say Japanese are Advanced in Technology.\\nWe are \\nINCREDIBLY\\nBRILLIANT INDIAN BRAINS\\n\\nShare it \\nDont laugh alone\\ufeff<|endoftext|>\"]\n",
      "tensor([[12115, 16868, 39947,  1268,  3691,   449,  2969,  1565, 33635, 39947,\n",
      "          1268,   532,  2750,  1583,  9995,    67, 15318,  1736,   292,   324,\n",
      "           554,  2869,    11,   287,   257, 19533,  9138,  1664,   262, 19533,\n",
      "          7021,   547,   925,    11,   198,  8524, 12908,   287,   257, 27074,\n",
      "          3348,  6338,   319,   281, 10474, 13878,   263, 10999,   198,   392,\n",
      "          3443, 11856,   287,  6383,   684,   986,   198,  7085,   257,  1661,\n",
      "           340,  3022,   326,   262, 27074,  4572, 12908,   262,  3348,  1231,\n",
      "         19533,    13,  1312,    13,    68,    13,   345,   550,   281,  6565,\n",
      "         19638,  1231, 19533,    13,   198,  2514, 13621,  1958,   428,  1917,\n",
      "           262,  4960,  1664,  5839,   257,  1395,    12,  2433, 27474,   422,\n",
      "           262,  1294,   329,   720,  1899,    11,   830,   284,  2198,   319,\n",
      "           262, 10474,  1627,  1771,   262,  9290,  7763, 19533,   290,  2492,\n",
      "           470,  6565,    13,   198,    32,  2092,  1917,  3022,   379,   399,\n",
      "          2533,    64,   523,  1686,    11,   287, 21157, 17325,   287, 24413,\n",
      "          3539,   492, 37571,   644,   484,   750,  9805,   198,  2990,  5839,\n",
      "           257,   275,  1228,  1228,  4336, 25894,  1088, 12820,    13, 33698,\n",
      "         16327,   290,  4624,   340,   319,   262,  5743,   286,   262, 10474,\n",
      "          1627,    13,   198,   464,  6565,  7917, 11799,    11,  1231,   523,\n",
      "          1686,   655, 17948,  1497, 10185,   198,  1870,   921, 13816,  4960,\n",
      "           389, 13435,   287,  8987,    13,   198,  1135,   389,   220,   198,\n",
      "          1268,  9419,  1961,    40,  9148,    56,   198,    33,  7112,  3069,\n",
      "            40,  8643, 24413, 16868, 39947, 20913,   198,   198, 11649,   340,\n",
      "           220,   198,    35,   756,  6487,  3436,   171,   119,   123, 50256]])\n",
      "tensor(4.5749, grad_fn=<NllLossBackward>)\n",
      "[\"I told my friend I watched The Two Towers and it was fun I've never seen him get so angry over a Lord Of The Rings film. <|endoftext|>\"]\n",
      "tensor([[   40,  1297,   616,  1545,   314,  7342,   383,  4930, 29031,   290,\n",
      "           340,   373,  1257,   314,  1053,  1239,  1775,   683,   651,   523,\n",
      "          7954,   625,   257,  4453,  3226,   383, 26028,  2646,    13, 50256]])\n",
      "tensor(3.8521, grad_fn=<NllLossBackward>)\n",
      "[\"I told myself I should stop drinking .. .. but I'm not about to listen to some weirdo that talks to himself<|endoftext|>\"]\n",
      "tensor([[   40,  1297,  3589,   314,   815,  2245,  7722, 11485, 11485,   475,\n",
      "           314,  1101,   407,   546,   284,  6004,   284,   617,  7650,    78,\n",
      "           326,  6130,   284,  2241, 50256]])\n",
      "tensor(4.3531, grad_fn=<NllLossBackward>)\n",
      "['I got fired for sticking my dick in the pickle slicer at work. She got fired too.<|endoftext|>']\n",
      "tensor([[   40,  1392,  6294,   329, 17274,   616, 19317,   287,   262,  2298,\n",
      "           293, 14369,   263,   379,   670,    13,  1375,  1392,  6294,  1165,\n",
      "            13, 50256]])\n",
      "tensor(4.8070, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d90bef2d55dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mjoke_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoke_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/conda_env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/conda_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=WARMUP_STEPS, t_total = -1)\n",
    "joke_count = 0\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    for idx,joke in enumerate(joke_loader):\n",
    "\n",
    "        joke_tens = torch.tensor(tokenizer.encode(joke[0])).unsqueeze(0).to(device)\n",
    "        print(joke)\n",
    "        print(joke_tens)\n",
    "                                 \n",
    "        outputs = model(joke_tens, labels=joke_tens)\n",
    "        loss, logits = outputs[:2]\n",
    "        print(loss)\n",
    "                                 \n",
    "        loss.backward()\n",
    "                       \n",
    "        joke_count = joke_count + 1\n",
    "        if joke_count == BATCH_SIZE:\n",
    "            joke_count = 0\n",
    "            optimizer.step()\n",
    "            scheduler.step()  \n",
    "            model.zero_grad()\n",
    "        \n",
    "      \n",
    "                                 \n",
    "    \n",
    "    output_list = list(cur_ids.squeeze().numpy())\n",
    "    output_text = tokenizer.decode(output_list)\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
