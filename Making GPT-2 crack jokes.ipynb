{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making GPT2 crack jokes\n",
    "\n",
    "This is simple experimental notebook for fine-tuning pretrained GPT2 model on jokes dataset. Let's see if it can learn to crack some jokes on it's own. \n",
    "\n",
    "For this purpose I will use pretrained models from huggingface [transformers repository](https://github.com/huggingface/transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 22:23:33.436547 4458931648 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /Users/martinsf/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I1029 22:23:33.445147 4458931648 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /Users/martinsf/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I1029 22:23:34.091546 4458931648 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /Users/martinsf/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
      "I1029 22:23:34.097579 4458931648 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "I1029 22:23:34.596061 4458931648 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /Users/martinsf/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ids = torch.tensor(tokenizer.encode(\" The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. \")).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
    "    choice = np.random.choice(n, 1, p = top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    \n",
    "    print(f\"top_prob: {top_prob} choice: {choice}\")\n",
    "    \n",
    "    return token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_prob: [9.3155722e-05 2.7247870e-04 9.8721393e-05 3.6263184e-04 9.9917305e-01] choice: [4]\n",
      "top_prob: [7.6523706e-05 9.9719161e-01 1.5862266e-04 2.4882520e-03 8.4984953e-05] choice: [1]\n",
      "top_prob: [1.2930277e-04 1.4282188e-04 7.4180745e-04 3.1581570e-03 9.9582785e-01] choice: [4]\n",
      "top_prob: [1.05494240e-04 3.54819087e-04 1.06825755e-04 9.99136746e-01\n",
      " 2.96109793e-04] choice: [3]\n",
      "top_prob: [6.9632268e-05 7.3165764e-05 2.5476173e-03 9.9714917e-01 1.6041707e-04] choice: [3]\n",
      "top_prob: [1.1009357e-04 1.1233866e-04 9.9666548e-01 6.1074464e-04 2.5013629e-03] choice: [2]\n",
      "top_prob: [1.11698915e-04 1.12981099e-04 3.05250345e-04 9.99158502e-01\n",
      " 3.11551237e-04] choice: [3]\n",
      "top_prob: [6.9391303e-05 7.8807207e-05 1.5586827e-04 2.6714613e-03 9.9702448e-01] choice: [4]\n",
      "top_prob: [9.6811564e-05 1.0963494e-04 9.9674791e-01 5.3356669e-04 2.5120892e-03] choice: [2]\n",
      "top_prob: [1.0886505e-04 1.1686112e-04 2.7823006e-04 3.0914496e-04 9.9918687e-01] choice: [4]\n",
      "top_prob: [7.6498691e-05 8.4220170e-05 1.4726172e-04 9.9695694e-01 2.7350872e-03] choice: [3]\n",
      "top_prob: [9.4811876e-05 1.1781717e-04 5.4221845e-04 3.3463673e-03 9.9589878e-01] choice: [4]\n",
      "top_prob: [1.07777625e-04 1.18706987e-04 3.10270058e-04 2.59941444e-04\n",
      " 9.99203324e-01] choice: [4]\n",
      "top_prob: [8.2086452e-05 9.1617374e-05 1.3913820e-04 2.7721133e-03 9.9691504e-01] choice: [4]\n",
      "top_prob: [1.0160399e-04 1.3570883e-04 6.3715974e-04 5.9535699e-03 9.9317199e-01] choice: [4]\n",
      "top_prob: [1.0707559e-04 1.1894401e-04 9.9921435e-01 3.0965390e-04 2.5000508e-04] choice: [2]\n",
      "top_prob: [8.6813903e-05 2.8010528e-03 1.0170814e-04 1.3172859e-04 9.9687868e-01] choice: [4]\n",
      "top_prob: [1.1727234e-04 1.5744881e-04 8.1975281e-04 9.8602849e-01 1.2877011e-02] choice: [3]\n",
      "top_prob: [1.07565487e-04 1.19482735e-04 2.46682408e-04 3.09489318e-04\n",
      " 9.99216795e-01] choice: [4]\n",
      "top_prob: [9.2550028e-05 1.1315268e-04 9.9682027e-01 1.2744249e-04 2.8466026e-03] choice: [2]\n",
      "top_prob: [1.5790139e-04 1.7755770e-04 1.1008129e-03 2.8960453e-02 9.6960330e-01] choice: [4]\n",
      "top_prob: [1.1003452e-04 1.2261196e-04 2.4907393e-04 3.1224187e-04 9.9920601e-01] choice: [4]\n",
      "top_prob: [9.6069831e-05 2.9077206e-03 9.9674726e-01 1.2329400e-04 1.2570275e-04] choice: [2]\n",
      "top_prob: [1.8185349e-04 2.0168083e-04 5.2036230e-02 9.4622785e-01 1.3523648e-03] choice: [3]\n",
      "top_prob: [1.1286262e-04 1.2525392e-04 3.1354101e-04 9.9919248e-01 2.5587351e-04] choice: [3]\n",
      "top_prob: [9.9789599e-05 1.2521003e-04 9.9663502e-01 1.3337289e-04 3.0066033e-03] choice: [2]\n",
      "top_prob: [1.7327923e-04 7.0901662e-02 2.1696971e-04 9.2722988e-01 1.4782009e-03] choice: [3]\n",
      "top_prob: [1.1571411e-04 1.2713169e-04 2.6303966e-04 3.1368562e-04 9.9918044e-01] choice: [4]\n",
      "top_prob: [1.03094324e-04 1.25311723e-04 1.42543824e-04 3.12805176e-03\n",
      " 9.96501029e-01] choice: [4]\n",
      "top_prob: [1.6416975e-04 8.4144942e-02 2.1536284e-04 9.1392535e-01 1.5501069e-03] choice: [3]\n",
      "top_prob: [1.1911400e-04 3.1597621e-04 2.7285027e-04 1.2953005e-04 9.9916250e-01] choice: [4]\n",
      "top_prob: [1.05459614e-04 1.24404090e-04 1.46917475e-04 3.23462393e-03\n",
      " 9.96388555e-01] choice: [4]\n",
      "top_prob: [1.6095866e-04 2.1969240e-04 9.0012237e-02 9.0801001e-01 1.5971041e-03] choice: [3]\n",
      "top_prob: [1.2121554e-04 3.1583727e-04 1.3029158e-04 9.9914986e-01 2.8280381e-04] choice: [3]\n",
      "top_prob: [1.0747882e-04 1.2391896e-04 9.9625081e-01 1.5133142e-04 3.3664515e-03] choice: [2]\n",
      "top_prob: [1.6622921e-04 9.0471566e-02 2.3510854e-04 9.0750551e-01 1.6216256e-03] choice: [1]\n",
      "top_prob: [0.00493896 0.00917084 0.36759618 0.01534345 0.6029506 ] choice: [4]\n",
      "top_prob: [2.5110945e-04 2.8910901e-04 7.1744301e-04 3.6831759e-04 9.9837404e-01] choice: [4]\n",
      "top_prob: [3.8717527e-04 5.9888692e-04 9.9609661e-01 2.0654004e-03 8.5189159e-04] choice: [2]\n",
      "top_prob: [0.00292111 0.00527893 0.00749458 0.35821941 0.626086  ] choice: [4]\n",
      "top_prob: [0.00229973 0.41889137 0.01579467 0.55937016 0.00364408] choice: [3]\n",
      "top_prob: [3.0833768e-04 9.9854130e-01 3.2573409e-04 3.9789380e-04 4.2679306e-04] choice: [1]\n",
      "top_prob: [3.4635092e-04 4.7589705e-04 1.5962895e-03 2.3560331e-03 9.9522543e-01] choice: [4]\n",
      "top_prob: [1.9841465e-04 3.7492532e-04 5.1403628e-04 2.0559512e-03 9.9685663e-01] choice: [4]\n",
      "top_prob: [8.6555367e-05 9.4099865e-05 2.5081573e-04 9.9930835e-01 2.6014732e-04] choice: [3]\n",
      "top_prob: [1.3019338e-04 1.3237282e-04 2.4822750e-04 2.7818738e-03 9.9670732e-01] choice: [4]\n",
      "top_prob: [1.2404284e-04 1.6504372e-04 5.3200405e-04 9.9727708e-01 1.9018104e-03] choice: [3]\n",
      "top_prob: [8.6681386e-05 9.4086026e-05 2.6681012e-04 2.6915729e-04 9.9928325e-01] choice: [4]\n",
      "top_prob: [7.6848934e-05 9.8372308e-05 2.7226107e-03 9.9693209e-01 1.7009664e-04] choice: [3]\n",
      "top_prob: [1.1007386e-04 1.8575870e-03 6.0426770e-04 1.1955335e-04 9.9730849e-01] choice: [4]\n",
      "top_prob: [9.9536803e-05 1.0844092e-04 3.0236712e-04 9.9920481e-01 2.8483756e-04] choice: [3]\n",
      "top_prob: [7.2010211e-05 1.6645058e-04 2.7210717e-03 7.8728932e-05 9.9696171e-01] choice: [4]\n",
      "top_prob: [9.3352253e-05 9.7128774e-05 4.9568253e-04 1.5253661e-03 9.9778849e-01] choice: [4]\n",
      "top_prob: [1.05835672e-04 3.17295606e-04 2.65701645e-04 1.16945805e-04\n",
      " 9.99194205e-01] choice: [4]\n",
      "top_prob: [7.3894451e-05 8.1115082e-05 1.6566708e-04 2.9795328e-03 9.9669981e-01] choice: [4]\n",
      "top_prob: [8.1110935e-05 9.3577750e-05 4.0671899e-04 9.9797291e-01 1.4456892e-03] choice: [3]\n",
      "top_prob: [1.09695364e-04 1.13132584e-04 2.38615277e-04 9.99216557e-01\n",
      " 3.22043838e-04] choice: [3]\n",
      "top_prob: [7.8819845e-05 8.8230940e-05 1.5758415e-04 3.1603361e-03 9.9651504e-01] choice: [4]\n",
      "top_prob: [7.7067380e-05 9.8282311e-05 3.7965161e-04 1.6756128e-03 9.9776936e-01] choice: [4]\n",
      "top_prob: [1.0633239e-04 1.1054795e-04 2.2239146e-04 9.9923784e-01 3.2291672e-04] choice: [3]\n",
      "top_prob: [8.3367879e-05 9.4533068e-05 9.9641556e-01 1.4778937e-04 3.2587389e-03] choice: [2]\n",
      "top_prob: [7.9008227e-05 1.0960840e-04 4.0724463e-04 2.3955943e-03 9.9700856e-01] choice: [4]\n",
      "top_prob: [1.04781204e-04 1.09481836e-04 9.99251664e-01 2.14018393e-04\n",
      " 3.19973420e-04] choice: [2]\n",
      "top_prob: [8.9327768e-05 1.0382144e-04 1.4120940e-04 3.3228199e-03 9.9634284e-01] choice: [4]\n",
      "top_prob: [8.6028725e-05 1.2588165e-04 9.9498773e-01 4.3117967e-03 4.8858474e-04] choice: [2]\n",
      "top_prob: [1.0408100e-04 1.0908428e-04 2.0774604e-04 3.1848089e-04 9.9926066e-01] choice: [4]\n",
      "top_prob: [9.36634096e-05 1.13657436e-04 1.36082032e-04 9.96283412e-01\n",
      " 3.37324641e-03] choice: [3]\n",
      "top_prob: [9.7261349e-05 1.4418890e-04 6.3611357e-04 9.3345083e-03 9.8978794e-01] choice: [4]\n",
      "top_prob: [1.0489550e-04 1.1040528e-04 2.0757766e-04 9.9925858e-01 3.1847536e-04] choice: [3]\n",
      "top_prob: [9.8777993e-05 1.2600592e-04 1.3370346e-04 9.9618262e-01 3.4588501e-03] choice: [3]\n",
      "top_prob: [1.1622829e-04 1.5981102e-04 8.4139709e-04 9.7823471e-01 2.0647839e-02] choice: [3]\n",
      "top_prob: [1.06424806e-04 3.19500279e-04 9.99252021e-01 2.10077633e-04\n",
      " 1.12023445e-04] choice: [2]\n",
      "top_prob: [1.0329847e-04 1.3417065e-04 1.3702795e-04 3.5858722e-03 9.9603963e-01] choice: [4]\n",
      "top_prob: [1.4879953e-04 1.6967012e-04 1.0663435e-03 3.8799711e-02 9.5981544e-01] choice: [4]\n",
      "top_prob: [1.0838053e-04 1.1415868e-04 2.1388917e-04 9.9924284e-01 3.2075270e-04] choice: [3]\n",
      "top_prob: [1.0707605e-04 1.3513806e-04 1.4709665e-04 9.9586993e-01 3.7407321e-03] choice: [3]\n",
      "top_prob: [1.6939243e-04 1.7724837e-04 1.2335619e-03 9.4035590e-01 5.8063932e-02] choice: [3]\n",
      "top_prob: [1.10935747e-04 1.16611445e-04 2.19242778e-04 3.23180429e-04\n",
      " 9.99230027e-01] choice: [4]\n",
      "top_prob: [1.10197005e-04 1.35681214e-04 1.54735448e-04 3.88321560e-03\n",
      " 9.95716155e-01] choice: [4]\n",
      "top_prob: [1.6193594e-04 1.9245927e-04 1.3297900e-03 9.2506748e-01 7.3248364e-02] choice: [3]\n",
      "top_prob: [1.13024231e-04 9.99219716e-01 2.26224132e-04 1.18074844e-04\n",
      " 3.23039014e-04] choice: [1]\n",
      "top_prob: [1.1281225e-04 1.3588458e-04 4.0381616e-03 9.9555153e-01 1.6161335e-04] choice: [3]\n",
      "top_prob: [1.6124116e-04 2.0020602e-04 8.0926783e-02 9.1733944e-01 1.3723415e-03] choice: [3]\n",
      "top_prob: [1.1403873e-04 1.1914922e-04 2.3066002e-04 3.2217574e-04 9.9921393e-01] choice: [4]\n",
      "top_prob: [1.1471384e-04 1.3637163e-04 1.6609467e-04 4.1759238e-03 9.9540693e-01] choice: [4]\n",
      "top_prob: [1.6129106e-04 2.0906722e-04 8.4184304e-02 9.1405994e-01 1.3854135e-03] choice: [3]\n",
      "top_prob: [1.1484149e-04 1.1922144e-04 3.2153094e-04 2.3479959e-04 9.9920958e-01] choice: [4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_prob: [1.1546009e-04 1.3526282e-04 1.6789863e-04 4.3118335e-03 9.9526954e-01] choice: [4]\n",
      "top_prob: [1.6469926e-04 2.1858762e-04 8.2392924e-02 9.1583848e-01 1.3853372e-03] choice: [3]\n",
      "top_prob: [1.1469612e-04 1.1911415e-04 9.9920946e-01 2.3727746e-04 3.1947202e-04] choice: [2]\n",
      "top_prob: [1.1615106e-04 1.3431473e-04 9.9511808e-01 1.6874884e-04 4.4627129e-03] choice: [2]\n",
      "top_prob: [1.7086152e-04 2.3052000e-04 1.3579886e-03 9.2097145e-01 7.7269159e-02] choice: [3]\n",
      "top_prob: [1.14097755e-04 2.37847329e-04 9.99212563e-01 3.17364378e-04\n",
      " 1.18133474e-04] choice: [2]\n",
      "top_prob: [1.1741950e-04 9.9496341e-01 4.6155457e-03 1.7046939e-04 1.3322030e-04] choice: [1]\n",
      "top_prob: [1.8262157e-04 2.3517874e-04 1.3104015e-03 9.2934632e-01 6.8925470e-02] choice: [3]\n",
      "top_prob: [1.12473746e-04 1.16514224e-04 9.99220073e-01 2.37102620e-04\n",
      " 3.13846482e-04] choice: [2]\n",
      "top_prob: [1.1724269e-04 1.7016077e-04 1.3180544e-04 4.7654207e-03 9.9481535e-01] choice: [4]\n",
      "top_prob: [1.8861878e-04 2.3218214e-04 1.2562952e-03 9.3727273e-01 6.1050225e-02] choice: [3]\n",
      "top_prob: [1.11297995e-04 1.15511080e-04 2.36096515e-04 3.12295393e-04\n",
      " 9.99224782e-01] choice: [4]\n",
      "top_prob: [1.17502444e-04 1.30397195e-04 1.69774416e-04 4.91826935e-03\n",
      " 9.94664073e-01] choice: [4]\n",
      "The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth.\n",
      "\n",
      "It is the world of the living, the living, the living, the living, the living. It is the world of the living, the living, the living, the living, the living. It is the world of the living, the living, the living. It is the world of the living, the living, the living, the living, the living, the living.\n",
      "\n",
      "It is the living, the living, the living, the living, the living, the living, the living. It is the world, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living. It is the world of the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living. It is the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living. It is the world, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living, the living\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in range(100):\n",
    "        outputs = model(cur_ids, labels=cur_ids)\n",
    "        loss, logits = outputs[:2]\n",
    "        softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(only one) batch and the last predicted embedding\n",
    "        next_token_id = choose_from_top(softmax_logits.numpy(), n=5) #Randomly(from the given probability distribution) choose the next word from the top n words\n",
    "        cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long() * next_token_id], dim = 1) # Add the last word\n",
    "\n",
    "    output_list = list(cur_ids.squeeze().numpy())\n",
    "    output_text = tokenizer.decode(output_list)\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
